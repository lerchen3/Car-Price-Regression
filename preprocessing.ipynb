{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "training_data = pd.read_csv('train.csv')  # 188533 rows, 13 columns - last column is price\n",
    "test_data = pd.read_csv('test.csv')  # 125690 rows\n",
    "\n",
    "def encode_columns(df):\n",
    "    df['hp'] = df['engine'].str.extract(r'(\\d+\\.?\\d*)HP').astype(float)\n",
    "    quantiles = [0.04 * cnt for cnt in range(26)]\n",
    "    bin_edges = df['hp'].quantile(quantiles).values\n",
    "    df['hp_bin'] = pd.cut(df['hp'], bins=bin_edges, labels=False, include_lowest=True) #bucket into 11 unique (was originally 348)\n",
    "    df['cylinder'] = df['engine'].str.extract(r'(\\d+\\.?\\d*) Cylinder').astype(float) #7 unique\n",
    "\n",
    "    df = df.drop(columns=['engine', 'hp'])\n",
    "    \n",
    "    df['got_V'] = df['model'].str.extract(r'(\\d+\\.?\\d*) V').notna().astype(int)\n",
    "    \n",
    "    df['clean_title'] = df['clean_title'].fillna('unknown')\n",
    "\n",
    "    df = df.drop(columns = ['id'])\n",
    "    return df\n",
    "\n",
    "training_data = encode_columns(training_data)\n",
    "test_data = encode_columns(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['price'] = 0  \n",
    "all_data = pd.concat([training_data, test_data], ignore_index=True)\n",
    "\n",
    "nan_cols = ['fuel_type', 'accident', 'hp_bin', 'cylinder']\n",
    "all_data['nans'] = 0              \n",
    "for nan_col_idx in range(4):\n",
    "    nan_col = nan_cols[nan_col_idx]\n",
    "    all_data['nans'] += all_data[nan_col].isna().astype(int) * (2 ** nan_col_idx) \n",
    "\n",
    "all_data.fillna({'fuel_type': 'unknown', 'accident': 'unknown', 'hp_bin' : -1, 'cylinder': -1}, inplace=True)\n",
    "\n",
    "training_data = all_data.head(188533).drop(columns = ['price'])\n",
    "y_train = all_data.head(188533)['price']\n",
    "test_data = all_data.loc[188533:(188533+125690)].drop(columns = ['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_val_weight = 1\n",
    "num_iterations = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def ordered_target_encode(train, test, y_train, categorical_features, prior_val_weight, num_iterations):\n",
    "    # Initialize new DataFrames with the same structure as train and test\n",
    "    new_train = pd.DataFrame(np.zeros(train.shape), columns=train.columns)\n",
    "    new_test = pd.DataFrame(np.zeros(test.shape), columns=test.columns)\n",
    "    \n",
    "    global_mean = y_train.mean()\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        # Shuffle the data\n",
    "        shuffled_indices = np.random.permutation(len(train))        \n",
    "        train_encoded = train.copy()\n",
    "        test_encoded = test.copy()\n",
    "        \n",
    "        for col in categorical_features:\n",
    "            # Initialize cumulative sum and count dictionaries\n",
    "            cumulative_sum = {}\n",
    "            cumulative_count = {}\n",
    "            \n",
    "            train_encoded_values = []\n",
    "\n",
    "            for idx in range(len(train)):\n",
    "                i = shuffled_indices[idx]\n",
    "                current_value = train.iloc[i][col]\n",
    "                current_target = y_train[i]\n",
    "\n",
    "                # Initialize cumulative sum and count if not already set for this category\n",
    "                if current_value not in cumulative_sum:\n",
    "                    cumulative_sum[current_value] = 0\n",
    "                    cumulative_count[current_value] = 0\n",
    "                \n",
    "                # Calculate the ordered target encoding with prior smoothing\n",
    "                numerator = cumulative_sum[current_value] + prior_val_weight * global_mean\n",
    "                denominator = cumulative_count[current_value] + prior_val_weight\n",
    "                \n",
    "                mean_value = numerator / denominator\n",
    "                \n",
    "                # Append the encoded value\n",
    "                train_encoded_values.append(mean_value)\n",
    "                \n",
    "                # Update the cumulative sum and count\n",
    "                cumulative_sum[current_value] += current_target\n",
    "                cumulative_count[current_value] += 1\n",
    "\n",
    "            # Apply the ordered encoding to the training data\n",
    "            train_encoded[col] = train_encoded_values\n",
    "            \n",
    "            # Apply the encoding to the test data using the cumulative sums and counts from training\n",
    "            test_encoded[col] = test[col].map(lambda x: (cumulative_sum.get(x, 0) + prior_val_weight * global_mean) / \n",
    "                                              (cumulative_count.get(x, 0) + prior_val_weight))\n",
    "        \n",
    "        # Update the overall encoded train and test DataFrames\n",
    "        new_train += train_encoded * (1 / num_iterations)\n",
    "        new_test += test_encoded * (1 / num_iterations)\n",
    "    \n",
    "    return new_train, new_test\n",
    "categorical_features = ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title', 'hp_bin', 'cylinder', 'got_V', 'nans']\n",
    "\n",
    "prior_val_weight = 10\n",
    "num_iterations = 9\n",
    "\n",
    "training_data, test_data = ordered_target_encode(training_data, test_data, y_train, categorical_features, prior_val_weight, num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.to_csv('training_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cars",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
