{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('train.csv') #188533 rows, 13 columns - last column is price\n",
    "test_data = pd.read_csv('test.csv') #125690 rows\n",
    "test_data['price'] = 0\n",
    "all_data = pd.concat([training_data, test_data], ignore_index = True)\n",
    "#clean_title, accident, fuel_type have \"NaN\" types\n",
    "all_data = all_data.drop(columns = [\"id\", \"model\", \"ext_col\", \"int_col\", \"clean_title\", \"engine\"])\n",
    "columns_to_process = ['brand', 'fuel_type', 'transmission']\n",
    "all_data.fillna({'fuel_type' : 'unknown'}, inplace = True)\n",
    "for column in columns_to_process:\n",
    "    mean_values = all_data.groupby(column)['price'].mean()\n",
    "    all_data[column] = all_data[column].map(mean_values)\n",
    "X_data = all_data.iloc[:, :-1]\n",
    "y_data = all_data.iloc[:, -1]\n",
    "X_data = pd.get_dummies(X_data, columns=['accident'], prefix='accident')\n",
    "X_data.rename(columns={'accident_At least 1 accident or damage reported': 'accident1'}, inplace=True)\n",
    "X_data.rename(columns={'accident_None reported': 'accident0'}, inplace=True)\n",
    "X_data = X_data.astype(int)\n",
    "scaler = StandardScaler()\n",
    "X_data = pd.DataFrame(scaler.fit_transform(X_data), columns=X_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_data.head(188533)\n",
    "y_train = y_data.head(188533)\n",
    "X_test = X_data.tail(125690)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "X_train = X_data.head(188533)\n",
    "y_train = y_data.head(188533)\n",
    "model.fit(X_train, y_train)\n",
    "X_test = X_data.tail(125690)\n",
    "y_pred = model.predict(X_test)\n",
    "id = np.array([idx for idx in range(188533, 314223)])\n",
    "prediction = pd.DataFrame({'id' : id, 'price' : y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ReLU(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def forwardpass(x, W1, b1, W2, b2):\n",
    "    Z1 = np.matmul(W1, x) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = np.matmul(W2, A1) + b2\n",
    "    return Z1, A1, Z2\n",
    "\n",
    "def backprop(x, Z1, A1, W2, A2, y):\n",
    "    dLdZ2 = A2\n",
    "    dLdZ2[y] -= 1  # Subtract 1 from the correct class\n",
    "    \n",
    "    dLdW2 = np.matmul(dLdZ2, A1.T)\n",
    "    dLdb2 = dLdZ2\n",
    "    \n",
    "    dLdA1 = np.matmul(W2.T, dLdZ2)\n",
    "    dLdZ1 = dLdA1 * (Z1 > 0)  # Element-wise multiplication for ReLU derivative\n",
    "    \n",
    "    dLdW1 = np.matmul(dLdZ1, x.T)\n",
    "    dLdb1 = dLdZ1\n",
    "\n",
    "    return dLdb1, dLdW1, dLdb2, dLdW2\n",
    "\n",
    "def gradient_descent(X, ys, W1, b1, W2, b2, num_iterations, alpha):  # alpha = learning rate!\n",
    "    for _ in range(num_iterations):\n",
    "        idx = np.random.randint(0, X.shape[1])\n",
    "        x = X[:, idx:idx+1]  # Keep x as a column vector\n",
    "        y = ys[idx]\n",
    "        Z1, A1, Z2, A2 = forwardpass(x, W1, b1, W2, b2)\n",
    "        dLdb1, dLdW1, dLdb2, dLdW2 = backprop(x, Z1, A1, W2, A2, y)\n",
    "        b1 -= dLdb1 * alpha\n",
    "        W1 -= dLdW1 * alpha\n",
    "        b2 -= dLdb2 * alpha\n",
    "        W2 -= dLdW2 * alpha\n",
    "    return b1, W1, b2, W2\n",
    "\n",
    "def gety(x, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forwardpass(x, W1, b1, W2, b2)\n",
    "    return np.argmax(A2, axis=0)\n",
    "\n",
    "# Initialize weights and biases\n",
    "b1 = np.random.normal(0, 1, size=(10, 1))\n",
    "W1 = np.random.normal(0, 1, size=(10, 784))\n",
    "b2 = np.random.normal(0, 1, size=(10, 1))\n",
    "W2 = np.random.normal(0, 1, size=(10, 10))\n",
    "\n",
    "# Train the model\n",
    "b1, W1, b2, W2 = gradient_descent(X_train, y_train, W1, b1, W2, b2, num_iterations=10**6, alpha=0.02)\n",
    "\n",
    "# Test the model\n",
    "numcorrect = 0\n",
    "totalnum = X_test.shape[1]\n",
    "for idx in range(totalnum):\n",
    "    x = X_test[:, idx:idx+1]  # Keep x as a column vector\n",
    "    y = y_test[idx]\n",
    "    if gety(x, W1, b1, W2, b2) == y:\n",
    "        numcorrect += 1\n",
    "\n",
    "print(f\"Accuracy: {numcorrect / totalnum * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = np.array([idx for idx in range(188533, 314223)])\n",
    "prediction = pd.DataFrame({'id' : id, 'price' : y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv('09052024carsprediction2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cars",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
