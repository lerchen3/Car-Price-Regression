{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import early_stopping, log_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input array must be 1 dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 22\u001b[0m\n\u001b[0;32m     17\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot_V\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*) V\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mnotna()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m---> 22\u001b[0m training_data \u001b[38;5;241m=\u001b[39m \u001b[43mencode_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m test_data \u001b[38;5;241m=\u001b[39m encode_columns(test_data)\n",
      "Cell \u001b[1;32mIn[73], line 8\u001b[0m, in \u001b[0;36mencode_columns\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_columns\u001b[39m(df):\n\u001b[0;32m      7\u001b[0m     quantiles \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhp_bin\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcut\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mengine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md+\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m.?\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md*)HP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mengine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md+\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m.?\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md*)HP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantiles\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_lowest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#bucket into 11 unique (was originally 348)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhp_bin\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcylinder\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*) Cylinder\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;66;03m#7 unique\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lerch\\miniconda3\\envs\\cars\\Lib\\site-packages\\pandas\\core\\reshape\\tile.py:242\u001b[0m, in \u001b[0;36mcut\u001b[1;34m(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# NOTE: this binning code is changed a bit from histogram for var(x) == 0\u001b[39;00m\n\u001b[0;32m    241\u001b[0m original \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m--> 242\u001b[0m x_idx \u001b[38;5;241m=\u001b[39m \u001b[43m_preprocess_for_cut\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m x_idx, _ \u001b[38;5;241m=\u001b[39m _coerce_to_type(x_idx)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39miterable(bins):\n",
      "File \u001b[1;32mc:\\Users\\lerch\\miniconda3\\envs\\cars\\Lib\\site-packages\\pandas\\core\\reshape\\tile.py:592\u001b[0m, in \u001b[0;36m_preprocess_for_cut\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    590\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput array must be 1 dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Index(x)\n",
      "\u001b[1;31mValueError\u001b[0m: Input array must be 1 dimensional"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv('train.csv')  # 188533 rows, 13 columns - last column is price\n",
    "test_data = pd.read_csv('test.csv')  # 125690 rows\n",
    "\n",
    "training_data = training_data.fillna('unknown')\n",
    "test_data = test_data.fillna('unknown')\n",
    "def encode_columns(df):\n",
    "    df['hp'] = df['engine'].str.extract(r'(\\d+\\.?\\d*)HP').astype(float)\n",
    "    quantiles = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "    df['hp_bin'] = pd.cut(df['hp'], bins=    bin_edges = df['hp'].quantile(quantiles).values\n",
    ", labels=False, include_lowest=True) #bucket into 11 unique (was originally 348)\n",
    "    df['hp_bin'].fillna(-1)\n",
    "\n",
    "    df['cylinder'] = df['engine'].str.extract(r'(\\d+\\.?\\d*) Cylinder').astype(float) #7 unique\n",
    "\n",
    "    df = df.drop(columns=['engine'])\n",
    "    \n",
    "    # Extract 'got_V' from 'model' column and convert to binary indicator\n",
    "    df['got_V'] = df['model'].str.extract(r'(\\d+\\.?\\d*) V').notna().astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "training_data = encode_columns(training_data)\n",
    "test_data = encode_columns(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "test_data['price'] = 0  # Add a dummy price column to test data\n",
    "all_data = pd.concat([training_data, test_data], ignore_index=True)\n",
    "\n",
    "categorical_features = ['brand', 'model', 'fuel_type', 'transmission', 'engine', 'ext_col', 'int_col', 'accident', 'clean_title']\n",
    "\n",
    "# Fill missing categorical values\n",
    "for nan_col in ['fuel_type', 'clean_title', 'brand', 'accident']:\n",
    "    all_data[f\"{nan_col} _nan\"] = all_data[nan_col].isna()\n",
    "all_data.fillna({'fuel_type': 'unknown', 'clean_title': 'unknown', 'brand': 'unknown', 'accident': 'unknown'}, inplace=True)\n",
    "X_data = all_data.drop(columns=['price'])\n",
    "\n",
    "for column in categorical_features:\n",
    "    value_counts = X_data[column].value_counts()\n",
    "    infrequent_values = value_counts[value_counts <= 169].index\n",
    "\n",
    "    # Replace infrequent values with 'other'\n",
    "    X_data[column] = X_data[column].replace(infrequent_values, 'other')\n",
    "\n",
    "# Perform one-hot encoding on all updated categorical columns at once\n",
    "X_data_one_hot = pd.get_dummies(X_data, columns=categorical_features)\n",
    "\n",
    "# Replace the original DataFrame with the one-hot encoded version\n",
    "X_data = X_data_one_hot\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numerical = ['model_year', 'milage']\n",
    "X_data[numerical] = pd.DataFrame(scaler.fit_transform(X_data[numerical]), columns=X_data[numerical].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randn(X_data.shape[1], X_data.shape[1]) \n",
    "Q, R = np.linalg.qr(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_data @ Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_data.drop(columns = 'id')\n",
    "y_train = training_data['price']\n",
    "\n",
    "X_data = X_data.to_numpy()\n",
    "y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "fold_number = 3\n",
    "num_models = 20\n",
    "\n",
    "models = []\n",
    "model_preds_train = np.zeros(shape=(num_models, 188533))\n",
    "model_preds_test = np.zeros(shape=(num_models, 125690))\n",
    "\n",
    "params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',  # Root Mean Squared Error\n",
    "        'num_leaves': 500,\n",
    "        'max_depth': 20,\n",
    "        'learning_rate': 0.01,\n",
    "        'n_estimators': 20000,   #it literally always early stops before it reaches here so no worries about this i think LOL\n",
    "        'subsample': 0.6,\n",
    "        'colsample_bytree': 0.9,\n",
    "        'reg_lambda': 0.4,\n",
    "        'min_data_in_leaf': 50,\n",
    "        'feature_fraction': 0.75,\n",
    "        'verbose': -1\n",
    "        }\n",
    "\n",
    "for model_number in range(num_models):\n",
    "    A = np.random.randn(X_data.shape[1], X_data.shape[1]) \n",
    "    Q, R = np.linalg.qr(A)\n",
    "    X_data = X_data @ Q\n",
    "    X_train = X_data[0:188533]\n",
    "    fold_size = 188533 // fold_number\n",
    "    indices = np.arange(188533)\n",
    "    np.random.shuffle(indices)    \n",
    "    train_predictions = np.zeros(188533)\n",
    "    test_predictions = np.zeros(125690)\n",
    "\n",
    "    print(f\"Now training model number {model_number}\")\n",
    "\n",
    "    for fold_idx in range(fold_number):\n",
    "        val_indices = indices[fold_idx* fold_size:(fold_idx+ 1) * fold_size]\n",
    "        train_indices = np.concatenate([indices[:fold_idx* fold_size], indices[(fold_idx+ 1) * fold_size:]])\n",
    "\n",
    "        X_train_fold, y_train_fold = X_train[train_indices], y_train[train_indices]\n",
    "        X_val_fold, y_val_fold = X_train[val_indices], y_train[val_indices]\n",
    "\n",
    "        train_data = lgb.Dataset(X_train_fold, label=y_train_fold)\n",
    "        valid_data = lgb.Dataset(X_val_fold, label=y_val_fold, reference=train_data)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=params['n_estimators'], \n",
    "            valid_sets=[valid_data],\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=50)], \n",
    "        )\n",
    "\n",
    "        train_predictions[val_indices] = model.predict(X_val_fold, num_iteration=model.best_iteration)\n",
    "        test_predictions += model.predict(X_data[188533:314223], num_iterations=model.best_iteration) * (1/fold_number)\n",
    "    train_predictions[0] = y_train[0]\n",
    "    print(mean_squared_error(train_predictions, y_train) ** (1/2))\n",
    "    if(mean_squared_error(train_predictions, y_train) ** (1/2) < 72500):\n",
    "        model_preds_train[model_number] = train_predictions\n",
    "        model_preds_test[model_number] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [20, 188533]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m model_preds_train \u001b[38;5;241m=\u001b[39m model_preds_train\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m      3\u001b[0m meta_model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmeta_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_preds_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m model_preds_test \u001b[38;5;241m=\u001b[39m model_preds_test\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m meta_model\u001b[38;5;241m.\u001b[39mpredict(model_preds_test)\n",
      "File \u001b[1;32mc:\\Users\\lerch\\miniconda3\\envs\\cars\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lerch\\miniconda3\\envs\\cars\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:609\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    605\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    607\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 609\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    618\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32mc:\\Users\\lerch\\miniconda3\\envs\\cars\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\lerch\\miniconda3\\envs\\cars\\Lib\\site-packages\\sklearn\\utils\\validation.py:1320\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1302\u001b[0m     X,\n\u001b[0;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1316\u001b[0m )\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1320\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\lerch\\miniconda3\\envs\\cars\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [20, 188533]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_preds_train = model_preds_train.T\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(model_preds_train, y_train)\n",
    "model_preds_test = model_preds_test.T\n",
    "y_pred = meta_model.predict(model_preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(y_pred)):\n",
    "    if(y_pred[idx] < 8000):\n",
    "        y_pred[idx] = 8000\n",
    "id = np.array([idx for idx in range(188533, 314223)])\n",
    "prediction = pd.DataFrame({'id' : id, 'price' : y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv('09182024carsprediction1.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cars",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
